name: Daily News Scraper

on:
  # Ejecutar diariamente a las 6:00 AM hora de PerÃº (UTC-5)
  schedule:
    - cron: '0 11 * * *'  # 11:00 UTC = 6:00 AM Peru time
  
  # Permitir ejecuciÃ³n manual desde GitHub Actions
  workflow_dispatch:
  
  # Ejecutar en push para testing (opcional)
  push:
    branches: [ main ]

jobs:
  scrape-and-deploy:
    runs-on: ubuntu-latest
    
    permissions:
      contents: write
      pages: write
      id-token: write
    
    steps:
    - name: Checkout repository
      uses: actions/checkout@v4
      with:
        fetch-depth: 0
    
    - name: Set up Python
      uses: actions/setup-python@v5
      with:
        python-version: '3.11'
    
    - name: Cache pip dependencies
      uses: actions/cache@v4
      with:
        path: ~/.cache/pip
        key: ${{ runner.os }}-pip-${{ hashFiles('**/requirements.txt') }}
        restore-keys: |
          ${{ runner.os }}-pip-
    
    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -r requirements.txt
        
    - name: Install additional system dependencies
      run: |
        sudo apt-get update
        sudo apt-get install -y jq
    
    - name: Set up Chrome for Selenium
      uses: browser-actions/setup-chrome@v1
      with:
        chrome-version: stable
    
    - name: Set up Chrome for Selenium
      uses: browser-actions/setup-chrome@v1
      with:
        chrome-version: stable

    - name: Create data directory
      run: mkdir -p data
    
    - name: Validate templates
      run: |
        echo "ğŸ” Validating templates..."
        python scripts/template_utils.py validate
        echo "âœ… Templates validation completed"
    
    - name: Run news scraper
      run: |
        echo "ğŸ•·ï¸ Starting news scraper..."
        python scripts/scraper.py
        echo "âœ… Scraping completed successfully"
    
    - name: Check scraped data
      run: |
        if [ -f data/news_$(date +%Y-%m-%d).json ]; then
          echo "âœ… News data file created successfully"
          echo "ğŸ“Š File size: $(du -h data/news_$(date +%Y-%m-%d).json | cut -f1)"
          echo "ğŸ“ˆ News count: $(jq '.total_news' data/news_$(date +%Y-%m-%d).json)"
        else
          echo "âŒ No news data file found"
          ls -la data/
          exit 1
        fi
    
    - name: Generate website
      run: |
        echo "ğŸ¨ Starting website generation..."
        python scripts/site_generator.py
        echo "âœ… Website generated successfully"
    
    - name: Verify generated site
      run: |
        if [ -f docs/index.html ]; then
          echo "âœ… Website HTML created successfully"
          echo "ğŸ“„ HTML file size: $(du -h docs/index.html | cut -f1)"
        else
          echo "âŒ Website HTML not found"
          ls -la docs/
          exit 1
        fi
    
    - name: Configure Git
      run: |
        git config --local user.email "action@github.com"
        git config --local user.name "GitHub Action"
    
    - name: Commit and push changes
      run: |
        git add data/ docs/
        if git diff --staged --quiet; then
          echo "No changes to commit"
        else
          git commit -m "ğŸ“° Daily news update - $(date +%Y-%m-%d)"
          git push
          echo "âœ… Changes committed and pushed"
        fi
    
    - name: Setup Pages
      uses: actions/configure-pages@v4
    
    - name: Upload to GitHub Pages
      uses: actions/upload-pages-artifact@v3
      with:
        path: './docs'
    
    - name: Deploy to GitHub Pages
      id: deployment
      uses: actions/deploy-pages@v4
    
    - name: Summary
      run: |
        echo "ğŸ‰ Daily scraping and deployment completed!"
        echo "ğŸ“Š Check the generated site at: ${{ steps.deployment.outputs.page_url }}"
        echo "ğŸ“… Date: $(date)"
        echo "ğŸ•·ï¸ Scraper: âœ… Completed"
        echo "ğŸ¨ Site Generator: âœ… Completed"
        echo "ğŸš€ Deployment: âœ… Completed"